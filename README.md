AI Red Team & Model Behavior Analysis Cases

A curated collection of AI Red Team test cases focusing on hallucination triggers, model behavior inconsistencies, safety boundary evaluation, and multi-model comparative analysis.
All cases follow a standardized structure: Summary → Mechanism → Findings → Risk.

This repository serves as a portfolio showcasing analytical ability, adversarial thinking, test design skills, and the capability to derive systematic conclusions from model behaviors.
